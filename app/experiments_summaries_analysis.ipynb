{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments Summaries Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "from utils import df_to_latex, summarize_tables, sum_table_to_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>ACHTUNG</b>: `experiments_path` ändern für verschiedene Zusammenfassungen.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = \"../data/analysis/experiments_summaries/experiment_summary_13\"\n",
    "vectorization_methods = [\"bow\", \"zscore\", \"tfidf\", \"cos\", \"zcos\"]\n",
    "drop_not_tuned = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeches corpus (only tuned classification methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_path = experiments_path + \"/speeches/all_classification_tables/\"\n",
    "speeches_clf_tables = glob.glob(speeches_path + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_dict = {}\n",
    "\n",
    "for vectorization_method in vectorization_methods:\n",
    "    speeches_dict[vectorization_method] = sum_table_to_df(summarize_tables(speeches_clf_tables, \n",
    "                                                                           speeches_path, \n",
    "                                                                           vectorization_method,\n",
    "                                                                           drop_not_tuned = drop_not_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_bow_df = speeches_dict[\"bow\"]\n",
    "speeches_zscore_df = speeches_dict[\"zscore\"]\n",
    "speeches_tfidf_df = speeches_dict[\"tfidf\"]\n",
    "speeches_cos_df = speeches_dict[\"cos\"]\n",
    "\n",
    "speeches_zcos_df = speeches_dict[\"zcos\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speeches DataFrames to latex tables (remove comment for desired table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\small\n",
      "\\begin{tabular}{c|cccc}\n",
      "\\hline\n",
      "& \\textbf{2000} & \\textbf{3000} & \\textbf{4000} & \\textbf{5000}\\\\\\hline\n",
      "\\textbf{SD-tKNN} & 0.508 (0.528) & 0.504 (0.587) & 0.535 (0.581) & 0.527 (0.573)\\\\\n",
      "\\textbf{SD-tNSC} & 0.542 (0.526) & 0.485 (0.559) & 0.531 (0.555) & 0.569 (0.572)\\\\\n",
      "\\textbf{tLSVM} & 0.727 (0.721) & 0.727 (0.723) & 0.704 (0.7) & 0.727 (0.697)\\\\\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "#print(df_to_latex(speeches_bow_df))\n",
    "#print(df_to_latex(speeches_zscore_df))\n",
    "#print(df_to_latex(speeches_tfidf_df))\n",
    "#print(df_to_latex(speeches_cos_df))\n",
    "print(df_to_latex(speeches_zcos_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced prose corpus (only tuned classification methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_prose_path = experiments_path + \"/red_prose/all_classification_tables/\"\n",
    "red_prose_clf_tables = glob.glob(red_prose_path + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_prose_dict = {}\n",
    "\n",
    "for vectorization_method in vectorization_methods:\n",
    "    red_prose_dict[vectorization_method] = sum_table_to_df(summarize_tables(red_prose_clf_tables, \n",
    "                                                                           red_prose_path, \n",
    "                                                                           vectorization_method,\n",
    "                                                                           drop_not_tuned = drop_not_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_prose_bow_df = red_prose_dict[\"bow\"]\n",
    "red_prose_zscore_df = red_prose_dict[\"zscore\"]\n",
    "red_prose_tfidf_df = red_prose_dict[\"tfidf\"]\n",
    "red_prose_cos_df = red_prose_dict[\"cos\"]\n",
    "\n",
    "red_prose_zcos_df = red_prose_dict[\"zcos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\small\n",
      "\\begin{tabular}{c|cccc}\n",
      "\\hline\n",
      "& \\textbf{2000} & \\textbf{3000} & \\textbf{4000} & \\textbf{5000}\\\\\\hline\n",
      "\\textbf{SD-tKNN} & 0.96 (0.963) & 0.972 (0.963) & 0.957 (0.965) & 0.967 (0.967)\\\\\n",
      "\\textbf{SD-tNSC} & 0.977 (0.972) & 0.99 (0.98) & 0.967 (0.987) & 0.98 (0.979)\\\\\n",
      "\\textbf{tLSVM} & 0.99 (0.98) & 0.995 (0.983) & 0.997 (0.992) & 0.99 (0.985)\\\\\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "#print(df_to_latex(red_prose_bow_df))\n",
    "#print(df_to_latex(red_prose_zscore_df))\n",
    "#print(df_to_latex(red_prose_tfidf_df))\n",
    "#print(df_to_latex(red_prose_cos_df))\n",
    "print(df_to_latex(red_prose_zcos_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prose corpus (only tuned classification methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prose_path = experiments_path + \"/prose/all_classification_tables/\"\n",
    "prose_clf_tables = glob.glob(prose_path + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 3 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d5596816b495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                         \u001b[0mprose_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                         \u001b[0mvectorization_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                                                         drop_not_tuned = drop_not_tuned))\n\u001b[0m",
      "\u001b[0;32m~/Desktop/informatik_programme/clf_stylo_comp/app/utils.py\u001b[0m in \u001b[0;36msummarize_tables\u001b[0;34m(files, path, vectorization_method, drop_not_tuned)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#TODO: better solution?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mclf_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mclf_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"clf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cv\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdrop_not_tuned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnlp/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5078\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5079\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5080\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5081\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5082\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnlp/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnlp/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    153\u001b[0m             raise ValueError(\n\u001b[1;32m    154\u001b[0m                 \u001b[0;34m'Length mismatch: Expected axis has {old} elements, new '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 'values have {new} elements'.format(old=old_len, new=new_len))\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 3 elements"
     ]
    }
   ],
   "source": [
    "prose_dict = {}\n",
    "\n",
    "for vectorization_method in vectorization_methods:\n",
    "    prose_dict[vectorization_method] = sum_table_to_df(summarize_tables(prose_clf_tables, \n",
    "                                                                        prose_path, \n",
    "                                                                        vectorization_method,\n",
    "                                                                        drop_not_tuned = drop_not_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prose_bow_df = prose_dict[\"bow\"]\n",
    "prose_zscore_df = prose_dict[\"zscore\"]\n",
    "prose_tfidf_df = prose_dict[\"tfidf\"]\n",
    "prose_cos_df = prose_dict[\"cos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>200</th>\n",
       "      <th>300</th>\n",
       "      <th>500</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "      <th>3000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tKNN</th>\n",
       "      <td>0.731 (0.615)</td>\n",
       "      <td>0.74 (0.641)</td>\n",
       "      <td>0.767 (0.674)</td>\n",
       "      <td>0.809 (0.69)</td>\n",
       "      <td>0.833 (0.72)</td>\n",
       "      <td>0.829 (0.738)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tNSC</th>\n",
       "      <td>0.529 (0.499)</td>\n",
       "      <td>0.581 (0.521)</td>\n",
       "      <td>0.62 (0.56)</td>\n",
       "      <td>0.672 (0.578)</td>\n",
       "      <td>0.731 (0.621)</td>\n",
       "      <td>0.739 (0.652)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tMNB</th>\n",
       "      <td>0.899 (0.845)</td>\n",
       "      <td>0.935 (0.878)</td>\n",
       "      <td>0.941 (0.896)</td>\n",
       "      <td>0.949 (0.913)</td>\n",
       "      <td>0.966 (0.915)</td>\n",
       "      <td>0.97 (0.926)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tLSVM</th>\n",
       "      <td>0.95 (0.883)</td>\n",
       "      <td>0.956 (0.888)</td>\n",
       "      <td>0.963 (0.899)</td>\n",
       "      <td>0.963 (0.899)</td>\n",
       "      <td>0.969 (0.895)</td>\n",
       "      <td>0.96 (0.902)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tLR</th>\n",
       "      <td>0.968 (0.945)</td>\n",
       "      <td>0.986 (0.955)</td>\n",
       "      <td>0.979 (0.953)</td>\n",
       "      <td>0.96 (0.9)</td>\n",
       "      <td>0.938 (0.834)</td>\n",
       "      <td>0.907 (0.793)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                200            300            500            1000  \\\n",
       "tKNN   0.731 (0.615)   0.74 (0.641)  0.767 (0.674)   0.809 (0.69)   \n",
       "tNSC   0.529 (0.499)  0.581 (0.521)    0.62 (0.56)  0.672 (0.578)   \n",
       "tMNB   0.899 (0.845)  0.935 (0.878)  0.941 (0.896)  0.949 (0.913)   \n",
       "tLSVM   0.95 (0.883)  0.956 (0.888)  0.963 (0.899)  0.963 (0.899)   \n",
       "tLR    0.968 (0.945)  0.986 (0.955)  0.979 (0.953)     0.96 (0.9)   \n",
       "\n",
       "                2000           3000  \n",
       "tKNN    0.833 (0.72)  0.829 (0.738)  \n",
       "tNSC   0.731 (0.621)  0.739 (0.652)  \n",
       "tMNB   0.966 (0.915)   0.97 (0.926)  \n",
       "tLSVM  0.969 (0.895)   0.96 (0.902)  \n",
       "tLR    0.938 (0.834)  0.907 (0.793)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prose_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prose DataFrames to latex tables (remove comment for desired table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_to_latex(prose_bow_df))\n",
    "#print(df_to_latex(prose_zscore_df))\n",
    "#print(df_to_latex(prose_tfidf_df))\n",
    "#print(df_to_latex(prose_cos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
