\documentclass[12pt,oneside]{article}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Zusaetzliche Pakete  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{acronym}
\usepackage{enumerate}  
\usepackage{a4wide}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{palatino}
\usepackage{blindtext}
\usepackage{multirow}
\usepackage[ruled,longend]{algorithm2e}

%folgende Zeile auskommentieren für englische Arbeiten
\usepackage[ngerman]{babel}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[bookmarks]{hyperref}
\usepackage[font=small,labelfont=bf,justification=justified, format=plain]{caption}
\captionsetup[figure]{justification=justified, singlelinecheck=off} 
\usepackage[style=authoryear-comp,natbib=true,backend=biber]{biblatex}
\usepackage{csquotes}
\addbibresource{literatur.bib}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Definition der Kopfzeile %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagestyle{fancy}
\fancyhf{}
\cfoot{\thepage}
\setlength{\headheight}{16pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  Definition des Deckblattes und der Titelseite  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\JMUTitle}[9]{

  \thispagestyle{empty}
  \vspace*{\stretch{1}}
  {\parindent0cm
  \rule{\linewidth}{.7ex}}
  \begin{flushright}
    \vspace*{\stretch{1}}
    \sffamily\bfseries\Huge
    #1\\
    \vspace*{\stretch{1}}
    \sffamily\bfseries\large
    #2
    \vspace*{\stretch{1}}
  \end{flushright}
  \rule{\linewidth}{.7ex}

  \vspace*{\stretch{1}}
  \begin{center}
    \includegraphics[width=2in]{siegel} \\
    \vspace*{\stretch{1}}
    \Large Seminararbeit  \\

    \vspace*{\stretch{2}}
   \large Institut für deutsche Philologie \\
          Lehrstuhl für Computerphilologie und Neuere Deutsche Literaturgeschichte\\
    \vspace*{\stretch{1}}
    \large Dozent:  #7 \\[1mm]
    
    \vspace*{\stretch{1}}
    \large W\"urzburg, den #6
  \end{center}
}

%% zusätzliche Pakete %%

\usepackage{float}
\usepackage{subcaption}
\usepackage[none]{hyphenat}
\sloppy
\usepackage{scrextend}
\deffootnote[1em]{1em}{1em}{\textsuperscript{\makebox[1em][l]{\thefootnotemark}}}
\usepackage{mathtools}
\usepackage[toc, page]{appendix}
\renewcommand\appendixtocname{Appendix}
\renewcommand\appendixpagename{Appendix}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  Beginn des Dokuments  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
  \JMUTitle
      {Autorschaftsattribution mithilfe von Machine Learning Verfahren und stilometrischen Verfahren (NUR DELTA). Eine vergleichende Analyse (TODO)} % Titel der Arbeit
      {Jan Paulus} % Vor- und Nachname des Autors
      
      {Institut für deutsche Philologie
Lehrstuhl für Computerphilologie und Neuere Deutsche Literaturgeschichte}  % Name der Fakultaet
      {W"urzburg 2020}                          % Ort und Jahr der Erstellung
      {14.02.2020 (TODO)}                              % Tag der Abgabe
      {Thorsten Vitt}               % Name des Erstgutachters
      {Zweitgutachter}                          % Name des Zweitgutachters
      {Pr"ufungsdatum}                          % Datum der muendlichen Pruefung

  \clearpage
\sloppy
\lhead{}
\pagenumbering{Roman} 
    \setcounter{page}{1}

\tableofcontents
\clearpage

\addcontentsline{toc}{section}{\listfigurename}
\listoffigures

\addcontentsline{toc}{section}{\listtablename}
\listoftables
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  Kurzzusammenfassung   %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\markboth{Zusammenfassung}{Zusammenfassung}
\section*{Zusammenfassung}
\blindtext
\clearpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  Einstellungen  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cleardoublepage
\pagenumbering{arabic}  
    \setcounter{page}{1}
\lhead{\nouppercase{\leftmark}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  Hauptteil  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Einleitung} 
\label{einleitung}

Bevor Burrows 2001 sein Delta-Maß vorstellte, war Forschungsstand im Bereich der Stilometrie, eine begrenzte Anzahl an voraussichtlich ähnlichen Texten miteinander zu vergleichen \citep[ii5]{evert2017}. Diese Vorgehensweise wird auch \glqq closed games\grqq{} genannt \citep[267]{burrows2002}. Bei \glqq open games\grqq{} hingegen gibt es hinsichtlich eines unbekannten Textes zuvor keinen Anhaltspunkt, welchen Kandidaten-Texten der unbekannte Text ähnlich ist. Das Ziel von Burrows Verfahren war es deshalb, diese \glqq open games\grqq{} in \glqq closed games\grqq{} zu transformieren \citep[268]{burrows2002}. Burrows verwendet dafür das Delta-Maß, welches die Ähnlichkeit über die Distanz von einem unbekannten Text zu einer Gruppe von Texten berechnet \citep[]{burrows2002}. Dieses Maß hat die folgenden Jahren der Stilometrie-Forschung geprägt \citep[ii5f.]{evert2017}. Als Alternative zum Delta-Maß wurden in den letzten Jahren auch vermehrt Machine Learning Verfahren wie K-Nearest Neighbors, Nearest Shrunken Neighbors oder Support Vector Machines verwendet \citep[S. 217]{jockers2010}. 
In dieser Arbeit soll Burrows Delta mithilfe von Nearest-Neighbor Verfahren als Klassifizierungsverfahren modelliert(AW?) werden. MEHR
Daraufhin soll ein Vergleich von Burrows Delta mit weiteren Klassifizierungsverfahren wie Support Vector Machines, Multinomial Naive Bayes und Logistic Regression durchgeführt werden.

\bigskip
TODO:
\begin{itemize}
    \item ZIEL DER ARBEIT: \glqq Das Ziel dieser Arbeit ist es, Burrows Delta mit einigen ausgewählten Machine Learning Klassifizierungsverfahren sowie Deep Learning Methoden (BERT) zu vergleichen. Dabei sollen die zu untersuchenden Verfahren nicht nur auf Genauigkeit getestet werden, sondern auch die Komplexität der Anwendung und Implementierung soll ein Bewertungsfaktor sein. Für die Vergleiche werden verschiedene Versuchszenarien erstellt wie feature-anzahl-veränderung usw. Diese Ergebnisse sollen nach einer Analyse ebenfalls in die Vergleichsbewertung mit einfliessen. \grqq{}
    \item hier werden quasi \glqq open games\grqq{} behandelt, auch wenn Korpus etwas eingeschränkt ist
    \item IN DIESER ARBEIT: Autorschaftsattribution (Teilgebiet der Stilometrie: https://programminghistorian.org/en/lessons/introduction-to-stylometry-with-python)
\end{itemize}

\bigskip
TODO:
\begin{itemize}
    \item ZETA auch als Maß nehmen (vllt noch weitere? und dann bert weglassen?) (ICH: eher nicht)
    \item RUDER angucken (siehe notizen)
    \item weiter literatur suchen mit begriff "authorship autribution"
    \item NSC: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestCentroid.html
    \item 
\end{itemize}


\section{Überblick über die Korpora}
\label{korpora}

TODO: "" austauschen

Für die Experimente in dieser Arbeit sollen zwei Korpora benutzt werden, um einen aussagekräftigen Vergleich der Stilometrie- und Klassifizierungsverfahren zu gewährleisten. Zudem wurde auf Basis dieser beiden Korpora mithilfe von Segmentierungen und anderen Auswahlkriterien (TODO: habe ich das gemacht?) noch zwei weitere Versionen erstellt, die ebenfalls für die Vergleiche der stilometrischen Methoden und den Machine Learning Klassifizierungsverfahren herangezogen wurden. Das erste Korpus besteht aus Reden von deutschen Politikern aus dem 21. Jahrhundert \citep[]{barbaresi2018}. Für die Benutzung in dieser Arbeit wurde es etwas bearbeitet. Zuerst wurden die Reden tokenisiert. Danach wurden die Namen der Redner aus den Reden entfernt, da dies eventuell die Klassifizierungen verfälschen könnte. Weiterhin wurde das Korpus auf 13 Redner mit jeweils 10 Reden gekürzt. Um eine Einheitlichkeit hinsichtlich der anderen Korpora (TODO: oder Korpus) zu gewährleisten, werden die Redner innerhalb dieser Arbeit als "Autoren" bezeichnet und ihre Reden als "Texte".

Das zweite Korpus stellt eine Variante des "Corpus of German-Language Fiction" von Frank Fischer und Jannik Strötgen dar \citep[]{fischer2017}. Ihr Korpus ist eine extrahierte und konvertierte Version von Werken aus dem "Projekt Gutenberg-DE". Das Korpus ist zweigeteilt: Der Großteil besteht aus deutschen Werken von deutschsprachigen Autoren, der kleinere Teil aus Werken von nicht-deutschsprachigen Autoren, die ins Deutsche übersetzt wurden. Der zweite Teil wird in dieser Arbeit ignoriert, da er einige Probleme aufweist wie teilweise nicht übersetzte Texte und fehlende Erscheinungsjahre. Der Teil des Korpus mit Werken von deutschsprachigen Autoren besteht aus 2735 Prosa Werken von 549 verschiedenen Autoren. Die Erscheinungsjahre erstrecken sich dabei von 1510 bis 1940, wobei der größte Teil der Werke zwischen 1840 und 1930 erschienen ist.\footnote{Dies wird auch durch Abbildung TODO bestätigt.} Die Einteilung der Werke in die Gattung Prosa ist sehr vage, da die Prosagattungen sehr mannigfaltig sind \citep[]{buecher} (TODO: Alternative?). Anhand des Korpus ist nicht erkennbar, zu welcher Prosagattung die einzelnen Werke gehören. Einige der Werke geben ihre Gattung zu Beginn des Textes an. Leider ist dies bei nur sehr wenigen Werken der Fall, eine einheitliche Angabe der Textgattung ist beim Original-Korpus nicht enthalten. Laut Angaben der Ersteller enthält das Korpus "mainly novels and short stories" \citep[]{fischer2017}. Das Korpus von Fischer und Strötgen wird für die Untersuchungen in dieser Arbeit vorverarbeitet und reduziert, die genaue Vorgehensweise befindet sich in Appendix B.




TODO hier: Segmentierung und andere Auswahl!
\begin{itemize}
    \item Segmentierung machen der Romane? damit bekommt man mehr romane, dafür sind die segmente nicht so lang (siehe SCHÖCH, zeta)
\item experimentaufbau in kapitel 2 von SCHÖCH, zeta angucken
\end{itemize}



\section{Stand der Forschung}

Eines der meist benutzten und ältesten Methoden der Stilometrie ist die Autorschaftsattribution. Die ersten Herangehensweise des Autorschaftsattributions-Probleme wurden bereits im späten 19. Jahrhundert entwickelt und werden
werden \glqq einheitliche invarianten Ansätze\grqq{} (engl.: \glqq Unitary Invariant Approach \grqq{}) genannt \citep[10]{argamon2009}. 1964 nutzten Mosteller und Wallace multivariaten Analyse-Ansätze (engl.: \glqq Multivariate Analysis Approach\grqq{}) bei der Untersuchung der Federalist Papers \citep[10]{argamon2009}. Der grundlegende Gedanke hinter diesen Ansätzen ist es, dass durch eine Darstellung aller zu untersuchenden Dokumente in einem mehrdimensionalen Raum der Autor eines unbekannten Dokuments durch ein Distanzmaß ermittelt werden kann: Der Autor des Dokuments, welches am nächsten zum unbekannten Dokument in diesem mehrdimensionalen Raum liegt, ist wahrscheinlich auch der Autor des unbekannten Dokuments \citep[11]{argamon2009}. Eine der bekanntesten dieser Methoden ist Burrows Delta, welches nach seiner Einführung 2001 maßgeblich die Autorschaftsattributions-Forschung der folgenden Jahre prägte \citep[ii5f]{evert2017}. (TODO ICH: hier burrows delta ausführlicher erklären? kann text strecken. ICH: einfaches Maß). Burrows Delta funktionierte in der Praxis sehr gut, jedoch waren die genauen Funktionsweisen (AW?) bis zur Erklärung durch Argamon ungeklärt. Der Ansatz von Argamon lieferte ein besseres Verständnis der grundlegenden Annahmen des Delta-Maßes, eine Einschränkung der Methoden sowie theoretisch fundierte Variationen und Erweiterungen des Maßes \citep[]{argamon2008}. Eine dieser Variationen ist die Auffassung von Burrows Delta als achsengewichtetes Nearest Neighbor Klassifizierungsverfahren \citep[132-135]{argamon2008}.


\bigskip

jockers 2010: zusammenfassung bei eder 2015 (169f.)

eder 2015: svm + n-grams angeblich beste kombo (koppel 2009, stratamos 2009); andere meinung ist, dass delta gleich gut wie svm (jockers 2010); n-gram nicht immer gut (eder 2015)

auch erwähnen: neben der Verwendung von Machine Learning Klassifizierungsverfahren auch Weiterentwicklung von Delta von Hoover oder Eder and Rybicki, 2013 (siehe EVERT, ii5) und SMITH, improving authorship ...

Die stilometrischen Verfahren wie Burrows Delta ähneln Machine Learning Verfahren (TODO: mehr). Der größte Unterschied zwischen den stilometrischen und den Machine Learning Verfahren 

\bigskip

TODO
\begin{itemize}
    \item EDER, 2015 (does size...)
    \begin{itemize}
        \item S. 169 r-u: SVM +  ngrams angeblich bester AA-Ansatz (ICH: hier Literatur der beiden genannten angucken) (notiz auch im nächsten kapitel)
        \item S. 170 l-o: ngrams nicht für alle Sprachen sehr effektiv (siehe EDER 2011)
    \end{itemize}

    
    \item TODO HIER: Jockers2010 (einleitung)
    Grundstein: Burrows Delta (brachte Forschung nach vorne)
    \item Argamon festigte Burrows Delta Methode. Zeigte hier auch schon Vorschläge für Klassifizierung (KNN)
    \item jockers zeigte machine learning verfahren
    \item ICH: hier an ebert sehr stark orientieren
    \item ICH: wenn NN, dann auch hier erzählen
\end{itemize}

NOTIZ: typischer vorgang stylo
\begin{itemize}
    \item document term matrix mit häufigkeiten
    \item matrix normalisieren
    \item dann irgendwie distanz berechnen
\end{itemize}

\section{Aufbau der Experimente}

TODO
\begin{itemize}
    \item ICH: Wie von Argamon bereits in seinem Paper zu ... vorgeschlagen wird Burrows Delta für die Experimente als Nearest Neighbors Classifier aufgefasst. Dies hilft vor allem bei dem Vergleich zwischen anderen Classifiern, da ein gleicher Aufbau gewährleistet werden kann (AF?!).
    \item JOCKERs text angucken, der beschreibt einige wichtige Maßnahmen, die stylom-Klassifizierung von normaler Dokument-Klassifizierung unterscheidet.
    \item 80/20 split (Pareto principle) erklären
    \item stratify erklären
    \item HOOVER, s. 470 (und bei burrows delta irgendwo): sagt, dass Erhöhung der Features die Accuracy erhöhen: das beweisen!? (notiz auch bei nächstem kapitel)
    \begin{itemize}
        \item hier aufbau erklären: 
        \item welche verfahren?
        \item was waren die ideen?
        \item was waren probleme?
        \item "Problematik bei Klassifizierung: viele Klassen, wenig Beispiele. Dies macht die Klassifizierung schwierig, auch im Hinblick der Evaluation, da cv der Cross Validation nicht größer als 2 sein darf (s.o.)"
    \end{itemize}
    \item ...
\end{itemize}


\section{Experimente}
\label{comparison}

TODO
\begin{itemize}
    \item HOOVER, s. 470 (und bei burrows delta irgendwo): sagt, dass Erhöhung der Features die Accuracy erhöhen: das beweisen!?
    \item EDER, 2015 (does size...), S. 169 rechts unten: SVM +  ngrams angeblich bester AA-Ansatz (ICH: hier Literatur der beiden genannten angucken)
    \item ICH: siehe hier Notizen von hackmd für vers. Experimente
    \item ICH: viele Grafiken
\end{itemize}

UMFANG (TODO weg): 
\begin{itemize}
    \item min 9 Seiten
    \item einleitende worte mit theorie
\end{itemize}

\section{Analyse der Experimente}

TODO
\begin{itemize}
    \item hier BURROWS/HOOVERS (S. 470) These, dass mehr features gleich bessere accuracy bei delta, analysieren
\end{itemize}

\section{Schlussbetrachtung}

TODO
\begin{itemize}
    \item 
\end{itemize}

\section{DELETE ME}

So gestaltet man eine Tabelle:
\newline
\begin{table}[H]
\caption{Beispielstabelle}
\centering
\begin{tabular}{llr}
\hline
A    & B & C \\
\hline
D      & per gram    & 11.65      \\
          & each        & 1.01       \\
E       & stuffed     & 32.54      \\
F       & stuffed     & 73.23      \\
G & frozen      & 8.39       \\
\hline
\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Literaturverzeichnis wird 
%% automatisch eingefügt
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\lhead{}
\printbibliography
\addcontentsline{toc}{section}{\bibname}

\begin{appendices}
\section{Daten und Code}
\label{appendix_a}

Im Ordner \glqq app\grqq{} befindet sich die Python-Datei \glqq utils.py\grqq{}, welche Nachbearbeitungs- und Reduktionsfunktionen für die Korpora beinhaltet. Die Dateien  \glqq texts\_to\_csv.py\grqq{} und \glqq classification.py\grqq{} sind CLI-Tools. Mithilfe von \glqq texts\_to\_csv.py\grqq{} können csv-Dateien der Korpora erstellt werden. Mit dem Tool \glqq classification.py\grqq{} wurden die verschiedenen Stilometrie-Experimente in dieser Arbeit durchgeführt. Mit \glqq visualization.py\grqq{} werden die Abbildungen anhand der Klassifikations-Ergebnisse visualisiert. Zudem befinden sich im Ordner \glqq app\grqq{} auch noch einige Jupyter-Notebooks, die zur Nachbearbeitung und Reduktion der Korpora genutzt und in der die Abbildungen, die sich in dieser Arbeit befinden, erzeugt wurden.

analysis.py noch erklären

\bigskip

in figures corpora analysis abbildungen für reduktion und so
in figures results klassifizierungsergebnisse

\bigskip
TODO: erklären, wo tools, code --> github project

\section{Reduktion des Prosa Korpus}
\label{appendix_b}

Das benutzte Korpus hat einige Probleme, weshalb es für die Untersuchungen in dieser Arbeit vorverarbeitet werden soll. Die Herangehensweise stützt sich dabei nicht auf eine 
literaturwissenschaftliche Wissensdomäne, sie soll eher auf schlichten Annahmen basieren. Die erste Veränderung soll eine Reduzierung des Korpus auf Werke sein, die zwischen 1840 und 1930 erschienen sind. Diese Aufteilung folgt der Aussage der Ersteller(AW?) des Korpus, dass der größte Teil der Werke des Korpus in diesem Zeitraum erschienen sei \citep[]{fischer2017}. Dies wird durch Abbildung 1 (TODO) bestätigt, die eine Verteilung der Werke nach Erscheinungsjahren darstellt. Der Grund für die Reduzierung ist die Komplexität bei der Klassifizierung, welche durch ein kleineres Korpus verringert wird. Das reduzierte Korpus enthält nach der Reduzierung nur noch 2212 Werke, etwa zwanzig Prozent der Werke wurde entfernt. Die Anzahl der verschiedenen Autoren hat sich von 549 auf 439 verringert.

\begin{figure}[!t]
\centering
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=1.0\linewidth]{figures/all_publication_years.png}
  \label{fig:all_publ}
\end{minipage}%
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=1.0\linewidth]{figures/reduced_publication_years.png}
  \label{fig:reduced_publ}
\end{minipage}
\caption[Häufigkeitsverteilung des Korpus]{Das linke Histogramm zeigt die Verteilung der Häufigkeit der Erscheinungsjahre des unbearbeiteten Korpus. Wie von Strötgen und Fischer angemerkt, wurden die meisten Werke des Korpus im Zeitraum zwischen 1840 und 1930 erstellt. Das rechte Histogramm zeigt die Verteilung nach der Entfernung der Erscheinungsjahre außerhalb des Zeitraums 1840 bis 1930.}
\end{figure}

Die Ersteller(?) des Korpus merken einige bekannte Probleme mit dem Korpus an \citep[]{fischer2017}. Fünf von neun dieser Probleme sind für eine Reduzierung uninteressant, da sie zum Beispiel außerhalb des Erscheinungszeitraums von 1840 und 1930 erschienen sind. Die anderen vier Probleme, bei denen es um Duplikate ging, wurden behoben, indem die problematischen Werke entfernt wurden. Nach der Entfernung bestand das Korpus noch aus 2208 Texten. 

Die verschiedenen Prosagattungen der einzelnen Texte sind nicht bekannt. Dies ist problematisch, da die Menge an verschiedenen Textgattungen bei der Klassifikation einen Bias\footnote{In dieser Arbeit wird der englische Begriff \glqq Bias \grqq{} anstelle des deutschen Begriffs \glqq systematischer Fehler \grqq{} benutzt.} erzeugen kann. Durch eine Reduzierung der Prosagattungen kann auch der Bias verringert werden. Da die Prosagattungen der einzelnen Texte jedoch unbekannt sind, werden hier die Textlängen als loser Indikator für die verschiedenen Prosagattungen verwendet. Die Annahme ist, dass kürzere Texte eine erhöhte Wahrscheinlichkeit haben, Prosagattungen wie \glqq Kurzgeschichte \grqq{}, \glqq Essay \grqq{}  oder \glqq Brief \grqq{} anzugehören. Da es jedoch keine eindeutigen Grenzen für die Einteilung von Prosagattungen gibt, wurde hier der Mittelwert ($ \overline{x} = 63870 $) als Trennwert verwendet.\footnote{Siehe Abbildung 2. (TODO)} Dieser ist aufgrund der großen Menge an kurzen Texten verzerrt. Nachdem die kürzeren Texte mithilfe des Mittelwerts entfernt wurden, sollen auch sehr lange Texte aus dem Korpus entfernt werden. Dies hat vor allem Performance-Gründe. Zuletzt wurden Autoren aus dem Korpus entfernt, von denen im Korpus weniger als drei Texte vorhanden waren.

\begin{figure}[!t]
\centering
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=1.0\linewidth]{figures/textlength_before.png}
  \label{fig:textlength_before}
\end{minipage}%
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=1.0\linewidth]{figures/textlength_after.png}
  \label{fig:textlength_after}
\end{minipage}
\caption[Reduzierung des Korpus anhand des Mittelwerts]{Die linke Grafik stellt die Häufigkeit von Texten anhand ihrer Textlänge dar. Sehr kurze Texte sind sehr häufig im Korpus und sehr lange Texte sind eher selten vertreten, die Verteilung ist also rechtsschief. Der Mittelwert der Gesamtheit aller Textlängen der Dokumente ist definiert als \( \overline{x} = \frac{\sum{L_D}}{count(D_i)}\), wobei \(L_D\) die Textlängen der einzelnen Texte und $ count(D_i) $ die Gesamtzahl aller Texte repräsentiert. Der Mittelwert $\overline{x} $ wird als Trennwert verwendet und alle Texte, deren Länge kürzer als der Mittelwert sind, werden aus dem Korpus entfernt. Die Verteilung der Texte anhand ihrer Textlängen nach dieser Reduzierung wird in der rechten Grafik dargestellt.}
\end{figure}

Neben der Reduktion des Korpus wurde noch einige Nachbearbeitungsmaßnahmen getroffen. Innerhalb der ursprünglichen Texte wurden zu Beginn Titel, Autor und Erscheinungsjahr des Textes genannt. Diese Informationen wurden aus den Texten entfernt. \footnote{Dies geschah in zwei Schritten: Zuerst wurde beim Einlesen der Texte ein Großteil der Meta-Informationen mithilfe eines regulären Ausdrucks entfernt. Dadurch konnten nicht alle Meta-Informationen beseitigt werden, da sich die Schreibweisen der Meta-Informationen von Titeln oder Autoren innerhalb des Textes teilweise geringfügig von den vorhandenen Meta-Informationen außerhalb des Textes unterschieden, wurde die Kosinus-Ähnlichkeit benutzt. Mit dieser wurde die Ähnlichkeit des Textanfangs jeweils mit Titel und Autor verglichen. Der Textanfang wurde dabei nach und nach vergrößert und iterativ mit dem Titel und Autor verglichen. Betrug die Ähnlichkeit gleich oder mehr als 60 Prozent, wurde der aktuelle Textanfang vom eigentlichen Text abgeschnitten und entfernt. Somit wurden auch einige andere Informationen als die Titel- und Autor-Informationen entfernt, die Menge ist jedoch im Vergleich der Textlänge so gering, dass dies keinen großen Einfluss auf die spätere stilometrische Analysen und Klassifizierungen haben sollte.} Die Befürchtung war es, dass bei einer Beibehaltung der Meta-Informationen im Text diese ein Einfluss auf die Ergebnisse der Klassifizierungen und stilometrischen Analysen haben und diese verfälschen könnten. Zuletzt wurden die Texte noch tokenisiert. 

\end{appendices}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Eidesstattliche Erklärung
%% muss angepasst werden 
%% in Erklaerung.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{Erklaerung.tex}

\end{document}